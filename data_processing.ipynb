{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f8a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282854e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (0.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a75293e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import shutil\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77db3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "drive_dir = Path('/content/drive/MyDrive')\n",
    "ucf_dir = drive_dir / \"UCF101/UCF-101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bc6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, test_dfs, val_dfs = [], [], []\n",
    "\n",
    "for path in ucf_dir.iterdir():\n",
    "    if path.is_dir():\n",
    "        folder_name = path.name\n",
    "\n",
    "        # find the .avi files\n",
    "        avi_paths = list(path.glob(\"*.avi\"))\n",
    "\n",
    "        # create train, val, test split 60, 20, 20\n",
    "        train_r, val_r, test_r = 0.6, 0.2, 0.2\n",
    "        X_train, X_val = train_test_split(avi_paths, train_size=train_r)\n",
    "        X_val, X_test = train_test_split(X_val, train_size= val_r / (val_r + test_r))\n",
    "\n",
    "        df_train = pd.DataFrame(X_train, columns=['path'])\n",
    "        df_train['action'] = folder_name\n",
    "\n",
    "        df_val = pd.DataFrame(X_val, columns=['path'])\n",
    "        df_val['action'] = folder_name\n",
    "\n",
    "        df_test = pd.DataFrame(X_test, columns=['path'])\n",
    "        df_test['action'] = folder_name\n",
    "\n",
    "        train_dfs.append(df_train)\n",
    "        val_dfs.append(df_val)\n",
    "        test_dfs.append(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "887dc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_dfs)\n",
    "val_df = pd.concat(val_dfs)\n",
    "test_df = pd.concat(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecd589b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3698527561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"UCF101/train_paths.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"UCF101/val_paths.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"UCF101/test_paths.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.to_csv(drive_dir / f\"UCF101/train_paths.parquet\", index=False)\n",
    "val_df.to_csv(drive_dir / f\"UCF101/val_paths.parquet\", index=False)\n",
    "test_df.to_csv(drive_dir / f\"UCF101/test_paths.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d2ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(drive_dir / f\"UCF101/train_paths.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bdcbafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = drive_dir / \"UCF101/logs\" \n",
    "log_path.mkdir(exist_ok=True)\n",
    "logger.remove()\n",
    "logger.add(str(log_path / \"first_frame_capture.log\"), level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85e49a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frame(frame, output_shape):\n",
    "    # convert the values from uint8 to float 32 and also normalize values\n",
    "    # frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "\n",
    "    # pad the image with black while preserving the aspect ratio\n",
    "    # frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "\n",
    "    frame = frame.astype(np.float32) / 255.0\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    target_h, target_w = output_shape\n",
    "    scale = min(target_h / h, target_w / w) # scale is selected so that the new image has a size that fits into target_h, target_w\n",
    "\n",
    "    new_h = int(h * scale)\n",
    "    new_w = int(w * scale)\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(frame, (new_w, new_h)) # the resize dim is width x height\n",
    "\n",
    "    # compute the padding\n",
    "    pad_h = (target_h - new_h) // 2\n",
    "    pad_w = (target_w - new_w) // 2\n",
    "\n",
    "    new_frame = np.zeros((target_h, target_w, 3))\n",
    "    new_frame[pad_h:pad_h + new_h, pad_w:pad_w + new_w] = resized\n",
    "    \n",
    "    return new_frame\n",
    "\n",
    "def capture_frames(video_path, frame_step=4, n_frames=32, output_size=(224, 224), mode='train'):\n",
    "    video_path = str(video_path)\n",
    "    video = cv2.VideoCapture(video_path) # open the video\n",
    "\n",
    "    if not video.isOpened():\n",
    "        video.release()\n",
    "        logger.warning(f'Failed to open video for {video_path}')\n",
    "        return\n",
    "\n",
    "    total_frames = video.get(cv2.CAP_PROP_FRAME_COUNT) # get total frame count\n",
    "    total_frames = int(total_frames) # cv2 return a float\n",
    "    required_frames = 1 + (n_frames - 1) * frame_step\n",
    "    result = []\n",
    "\n",
    "    if required_frames > total_frames:\n",
    "        start = 0 # if the required frames is greater than total frames available then we start sampling from the first frame\n",
    "    else: \n",
    "        # otherwise we pick a random starting point\n",
    "        max_start = total_frames - required_frames\n",
    "\n",
    "        # during inference or validation the start is not random\n",
    "        if mode == 'train':\n",
    "            start = random.randint(0, max_start) # 0 and max_start are inclusive\n",
    "        else:\n",
    "            start = 0\n",
    "    \n",
    "    # move the pointer to start\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "    # capture the first frame\n",
    "    # ret is a boolean indicating if frame was captured successfully\n",
    "    # frame is a numpy array of image (height, width, 3 channels BGR)\n",
    "    ret, frame = video.read() \n",
    "    if ret:\n",
    "        result.append(format_frame(frame, output_size))\n",
    "        logger.info(f'First frame captured from {video_path}')\n",
    "    else:\n",
    "        result.append()\n",
    "        logger.warning(f'Failed to capture first frame from {video_path}')\n",
    "        return \n",
    "    \n",
    "    # now start capturing remaining frames\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            # skip frame_step number of frames\n",
    "            ret, frame = video.read()\n",
    "        if ret: # store the last frame in since skipping frame_step\n",
    "            result.append(format_frame(frame, output_size))\n",
    "        else:\n",
    "            result.append(np.zeros_like(result[0]))\n",
    "    \n",
    "    video.release()\n",
    "    # this [..., [2, 1, 0]] reads as all dimensions before the last one\n",
    "    # [2, 1, 0] change channel order from BGR to RGB\n",
    "    result_arr = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f98cf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_df.path.values, train_df.action.values))\n",
    "dataset = dataset.map(\n",
    "    lambda path, label: tf.py_function(\n",
    "        lambda p, l: (capture_frames(p.numpy().decode('utf-8')), l),\n",
    "        [path, label],\n",
    "        [tf.float32, tf.string]\n",
    "    )\n",
    ")\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "# for frames, label in dataset:\n",
    "#     print(frames.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b59554ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will make the game scenes...\n",
    "for frames, label in dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8c3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbb345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
